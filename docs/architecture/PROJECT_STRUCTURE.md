# Project Structure

Complete directory tree of the PhoneticHybrid system.

```
phoneizer/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                      # Main project documentation
â”œâ”€â”€ ğŸ“„ SETUP_GUIDE.md                 # Installation & setup instructions
â”œâ”€â”€ ğŸ“„ DEPLOYMENT.md                  # Production deployment guide
â”œâ”€â”€ ğŸ“„ CONTRIBUTING.md                # Contribution guidelines
â”œâ”€â”€ ğŸ“„ LICENSE                        # MIT License
â”œâ”€â”€ ğŸ“„ PROJECT_STRUCTURE.md           # This file
â”œâ”€â”€ ğŸ“„ .gitignore                     # Git ignore patterns
â”œâ”€â”€ ğŸš€ start_dev.bat                  # Windows dev server launcher
â”œâ”€â”€ ğŸš€ start_dev.sh                   # macOS/Linux dev server launcher
â”‚
â”œâ”€â”€ ğŸ“ frontend/                      # React + MUI Application
â”‚   â”œâ”€â”€ ğŸ“„ package.json               # Node dependencies
â”‚   â”œâ”€â”€ ğŸ“„ tsconfig.json              # TypeScript config
â”‚   â”œâ”€â”€ ğŸ“„ tsconfig.node.json         # Node-specific TS config
â”‚   â”œâ”€â”€ ğŸ“„ vite.config.ts             # Vite bundler config
â”‚   â”œâ”€â”€ ğŸ“„ index.html                 # HTML entry point
â”‚   â”œâ”€â”€ ğŸ“„ README.md                  # Frontend documentation
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ src/
â”‚       â”œâ”€â”€ ğŸ“„ main.tsx               # App entry + theme setup
â”‚       â”œâ”€â”€ ğŸ“„ App.tsx                # Main app component & routing
â”‚       â”œâ”€â”€ ğŸ“„ vite-env.d.ts          # Vite type definitions
â”‚       â”‚
â”‚       â””â”€â”€ ğŸ“ components/
â”‚           â”œâ”€â”€ ğŸ“„ Welcome.tsx        # Landing/welcome screen
â”‚           â”œâ”€â”€ ğŸ“„ ConsentForm.tsx    # KVKK & personal info form
â”‚           â”œâ”€â”€ ğŸ“„ LikertScale.tsx    # Reusable survey component
â”‚           â”œâ”€â”€ ğŸ“„ OrthodonticSurvey.tsx  # Survey flow
â”‚           â”œâ”€â”€ ğŸ“„ PronunciationTest.tsx  # Audio recording interface
â”‚           â””â”€â”€ ğŸ“„ FinishScreen.tsx   # Completion screen
â”‚
â”œâ”€â”€ ğŸ“ backend/                       # FastAPI Server
â”‚   â”œâ”€â”€ ğŸ“„ main.py                    # API endpoints + ML inference
â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt           # Python dependencies
â”‚   â”œâ”€â”€ ğŸ“„ .env.example               # Environment variables template
â”‚   â””â”€â”€ ğŸ“„ README.md                  # Backend documentation
â”‚
â”œâ”€â”€ ğŸ“ ml_colab/                      # Google Colab Training
â”‚   â”œâ”€â”€ ğŸ““ training_notebook.ipynb    # Complete training pipeline
â”‚   â”œâ”€â”€ ğŸ“„ training_environment_setup.txt      # Colab setup guide
â”‚   â””â”€â”€ ğŸ“„ ai_training_instructions.txt        # Detailed training steps
â”‚
â”œâ”€â”€ ğŸ“ models/                        # Trained ML Models
â”‚   â”œâ”€â”€ ğŸ“„ .gitkeep                   # Keep directory in Git
â”‚   â””â”€â”€ ğŸ¤– trained_model.pt           # Trained PyTorch model (after training)
â”‚
â””â”€â”€ ğŸ“ data/                          # Participant Data
    â”œâ”€â”€ ğŸ“„ .gitkeep                   # Keep directory in Git
    â”‚
    â””â”€â”€ ğŸ“ participant_{uuid}/        # Per-participant folder
        â”œâ”€â”€ ğŸ“„ info.json              # Personal information
        â”œâ”€â”€ ğŸ“„ survey.json            # Survey responses
        â”‚
        â””â”€â”€ ğŸ“ kelimeler/             # Audio recordings
            â”œâ”€â”€ ğŸµ 00_araba.wav
            â”œâ”€â”€ ğŸµ 01_bahÃ§e.wav
            â”œâ”€â”€ ğŸµ 02_Ã§ocuk.wav
            â”œâ”€â”€ ğŸ“„ 00_araba_result.json
            â”œâ”€â”€ ğŸ“„ 01_bahÃ§e_result.json
            â””â”€â”€ ...
```

## File Descriptions

### Root Level

| File | Purpose |
|------|---------|
| `README.md` | Project overview, architecture, quick start |
| `SETUP_GUIDE.md` | Detailed installation instructions |
| `DEPLOYMENT.md` | Production deployment strategies |
| `CONTRIBUTING.md` | Guidelines for contributors |
| `LICENSE` | MIT License text |
| `.gitignore` | Files to exclude from Git |
| `start_dev.bat` | Windows script to launch dev servers |
| `start_dev.sh` | Unix script to launch dev servers |

### Frontend Structure

```
frontend/
â”œâ”€â”€ Configuration Files
â”‚   â”œâ”€â”€ package.json          # Dependencies: React, MUI, TypeScript
â”‚   â”œâ”€â”€ tsconfig.json         # TypeScript compiler settings
â”‚   â”œâ”€â”€ vite.config.ts        # Vite build tool + proxy config
â”‚   â””â”€â”€ index.html            # HTML shell
â”‚
â”œâ”€â”€ Source Code
â”‚   â”œâ”€â”€ main.tsx              # App initialization + MUI theme
â”‚   â””â”€â”€ App.tsx               # Route management & state
â”‚
â””â”€â”€ Components (src/components/)
    â”œâ”€â”€ Welcome.tsx           # Hero section with "Start" button
    â”œâ”€â”€ ConsentForm.tsx       # KVKK consent + personal data collection
    â”œâ”€â”€ LikertScale.tsx       # 5-point scale survey widget
    â”œâ”€â”€ OrthodonticSurvey.tsx # 8-question survey interface
    â”œâ”€â”€ PronunciationTest.tsx # Core recording logic (MediaRecorder API)
    â””â”€â”€ FinishScreen.tsx      # Thank you page with restart option
```

### Backend Structure

```
backend/
â”œâ”€â”€ main.py                   # FastAPI app with 5 endpoints:
â”‚                             #   - GET  / (health)
â”‚                             #   - POST /register
â”‚                             #   - POST /survey
â”‚                             #   - POST /upload
â”‚                             #   - GET  /health
â”‚
â”œâ”€â”€ requirements.txt          # Python packages:
â”‚                             #   - fastapi, uvicorn
â”‚                             #   - torch, librosa
â”‚                             #   - praat-parselmouth
â”‚                             #   - phonemizer
â”‚
â””â”€â”€ .env.example              # Configuration template
```

### ML Training Structure

```
ml_colab/
â”œâ”€â”€ training_notebook.ipynb   # Jupyter notebook with:
â”‚                             #   - Data loading from Drive
â”‚                             #   - Feature extraction (37 features)
â”‚                             #   - Model training (PyTorch)
â”‚                             #   - Evaluation & export
â”‚
â”œâ”€â”€ training_environment_setup.txt    # Colab environment guide:
â”‚                                    #   - Dependencies
â”‚                                    #   - GPU setup
â”‚                                    #   - Troubleshooting
â”‚
â””â”€â”€ ai_training_instructions.txt      # Step-by-step training:
                                      #   - Pre-training checklist
                                      #   - Training workflow
                                      #   - Hyperparameter tuning
```

### Data Structure

```
data/
â””â”€â”€ participant_{uuid}/
    â”œâ”€â”€ info.json             # {name, age, gender, consent, timestamp}
    â”œâ”€â”€ survey.json           # {responses: [1-5, ...], timestamp}
    â”‚
    â””â”€â”€ kelimeler/
        â”œâ”€â”€ 00_araba.wav      # Audio recording (16kHz WAV)
        â”œâ”€â”€ 00_araba_result.json  # {word, score, confidence, feedback}
        â”œâ”€â”€ 01_bahÃ§e.wav
        â”œâ”€â”€ 01_bahÃ§e_result.json
        â””â”€â”€ ...
```

## Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚
â”‚  (Frontend) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 1. User fills form
       â”‚ 2. Records audio
       â”‚ 3. Sends POST /upload
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI   â”‚
â”‚  (Backend)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 4. Saves to /data
       â”‚ 5. Loads audio
       â”‚ 6. Extracts features (37D)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ML Model   â”‚
â”‚  (PyTorch)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 7. Inference
       â”‚ 8. Returns score
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Backend   â”‚
â”‚  (FastAPI)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 9. Saves result.json
       â”‚ 10. Returns to frontend
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚
â”‚  (Display)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Dependencies

### Frontend Dependencies
```
React 18
â”œâ”€â”€ @mui/material (UI components)
â”œâ”€â”€ @emotion/react (CSS-in-JS)
â””â”€â”€ react-router-dom (routing)
```

### Backend Dependencies
```
FastAPI
â”œâ”€â”€ uvicorn (ASGI server)
â”œâ”€â”€ PyTorch (ML inference)
â”œâ”€â”€ librosa (audio processing)
â”œâ”€â”€ praat-parselmouth (phonetic analysis)
â””â”€â”€ phonemizer (IPA transcription)
```

## Key Features by File

### Frontend

| Component | Features |
|-----------|----------|
| `Welcome.tsx` | Hero section, gradient title, start button |
| `ConsentForm.tsx` | Validation, KVKK text, API integration |
| `LikertScale.tsx` | 5-point scale, hover effects, accessibility |
| `OrthodonticSurvey.tsx` | Progress bar, validation, 8 questions |
| `PronunciationTest.tsx` | MediaRecorder, upload, real-time feedback |
| `FinishScreen.tsx` | Completion message, restart functionality |

### Backend

| Function | Purpose |
|----------|---------|
| `register_participant()` | Create UUID, save info.json |
| `save_survey()` | Validate & save survey.json |
| `upload_audio()` | Save WAV, extract features, run inference |
| `extract_features()` | 13 MFCCs + spectral + formants + F0 |
| `analyze_pronunciation()` | ML inference, score generation |

## File Sizes (Approximate)

| File/Directory | Size |
|----------------|------|
| `frontend/node_modules/` | ~200 MB |
| `backend/venv/` | ~500 MB |
| `models/trained_model.pt` | ~1-2 MB |
| Source code total | ~500 KB |
| Per participant data | ~2-5 MB |

## Ports & URLs

| Service | Port | URL |
|---------|------|-----|
| Frontend Dev | 3000 | http://localhost:3000 |
| Backend API | 8000 | http://localhost:8000 |
| API Docs | 8000 | http://localhost:8000/docs |
| Redoc | 8000 | http://localhost:8000/redoc |

## Configuration Files

| File | Purpose |
|------|---------|
| `frontend/package.json` | Node dependencies, scripts |
| `frontend/tsconfig.json` | TypeScript compiler options |
| `frontend/vite.config.ts` | Dev server, proxy, build config |
| `backend/requirements.txt` | Python package versions |
| `backend/.env` | Environment variables (not in Git) |
| `.gitignore` | Exclude: node_modules, venv, data, models |

## Important Notes

1. **Git Ignored**: `node_modules/`, `venv/`, `data/`, `*.pt` files
2. **Required Before Training**: Collect participant data first
3. **Model File**: Must be copied from Colab to `models/` after training
4. **CORS**: Backend allows localhost:3000 and localhost:5173
5. **Audio Format**: WAV files, resampled to 16kHz for analysis
