# PhoneticHybrid ğŸ™ï¸

A production-ready Turkish pronunciation analysis platform using **Whisper (OpenAI)** + **Phonemizer** for academic phoneme-level pronunciation assessment.

## ğŸ¯ Overview

PhoneticHybrid is a full-stack web platform where participants:
1. Record Turkish words
2. Audio is analyzed using Whisper speech recognition (local, open-source)
3. Receive detailed phoneme-level pronunciation feedback
4. Get actionable insights based on acoustic features

**Perfect for:** Linguistic research, speech therapy, language learning applications, pronunciation assessment

**Key Features:**
- âœ… **Zero API costs** - Runs completely locally
- ğŸ”’ **Privacy-first** - Audio never leaves your machine
- ğŸŒ **Open-source** - No API keys or credentials needed
- ğŸ‡¹ğŸ‡· **Excellent Turkish support** - Pre-trained multilingual model

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              WHISPER-BASED ARCHITECTURE (LOCAL)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Frontend   â”‚â”€â”€â”€â”€â”€â–¶â”‚   Backend    â”‚â”€â”€â”€â”€â”€â–¶â”‚   Whisper    â”‚ â”‚
â”‚  â”‚ React + MUI  â”‚â—€â”€â”€â”€â”€â”€â”‚   FastAPI    â”‚â—€â”€â”€â”€â”€â”€â”‚  (Local AI)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                               â”‚                                  â”‚
â”‚                               â”œâ”€â”€â”€â”€â”€â–¶ Phonemizer (eSpeak NG)    â”‚
â”‚                               â”œâ”€â”€â”€â”€â”€â–¶ Acoustic Analysis         â”‚
â”‚                               â”‚       (librosa, Praat)          â”‚
â”‚                               â””â”€â”€â”€â”€â”€â–¶ Phoneme Alignment         â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tech Stack

**Frontend:**
- React 18
- Material UI v6
- TypeScript
- Vite

**Backend:**
- FastAPI (Python 3.10+)
- Whisper (OpenAI open-source speech recognition)
- Phonemizer (eSpeak NG backend)
- librosa (audio processing)
- praat-parselmouth (phonetic analysis)
- scipy (phoneme alignment)

**Analysis Pipeline:**
- Whisper Speech-to-Text (local, multilingual)
- Ground-truth phoneme generation (Phonemizer)
- Acoustic feature extraction (MFCCs, formants, F0)
- Phoneme-level alignment and scoring

## ğŸ“ Project Structure

```
phoneizer/
â”œâ”€â”€ frontend/                # React + MUI application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Welcome.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ConsentForm.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ LikertScale.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ OrthodonticSurvey.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ PronunciationTest.tsx
â”‚   â”‚   â”‚   â””â”€â”€ FinishScreen.tsx
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â”œâ”€â”€ backend/                 # FastAPI server
â”‚   â”œâ”€â”€ main.py             # API endpoints + ML inference
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ ml_colab/               # Google Colab training
â”‚   â”œâ”€â”€ training_notebook.ipynb
â”‚   â”œâ”€â”€ training_environment_setup.txt
â”‚   â””â”€â”€ ai_training_instructions.txt
â”‚
â”œâ”€â”€ models/                 # Trained ML models
â”‚   â””â”€â”€ trained_model.pt   # (created after training)
â”‚
â”œâ”€â”€ data/                   # Participant data
â”‚   â””â”€â”€ participant_xxx/
â”‚       â”œâ”€â”€ info.json
â”‚       â”œâ”€â”€ survey.json
â”‚       â””â”€â”€ kelimeler/
â”‚           â””â”€â”€ *.wav
â”‚
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites

- **Node.js** 18+ and npm
- **Python** 3.10+
- **eSpeak-NG** (for phoneme generation)

### Automated Setup (Recommended)

Choose your operating system and run the setup script:

**macOS:**
```bash
./scripts/setup/setup-macos.sh
```

**Linux:**
```bash
./scripts/setup/setup-linux.sh
```

**Windows:**
```cmd
scripts\setup\setup-windows.bat
```

The setup script will:
- âœ… Verify prerequisites (Python, Node.js, eSpeak-NG)
- âœ… Install eSpeak-NG if missing (macOS/Linux)
- âœ… Create Python virtual environment
- âœ… Install all Python dependencies
- âœ… Install all Node.js dependencies
- âœ… Create configuration files

### Start Development Servers

**macOS:**
```bash
./scripts/start/start-macos.sh
```

**Linux:**
```bash
./scripts/start/start-linux.sh
```

**Windows:**
```cmd
scripts\start\start-windows.bat
```

### Access Application

- **Frontend:** http://localhost:5173 (or http://localhost:3000)
- **Backend:** http://localhost:8000
- **API Docs:** http://localhost:8000/docs

**Note:** On first run, Whisper will download a ~150MB model (takes 1-2 minutes)

## ğŸ“ How It Works (Whisper-Based Approach)

### Analysis Pipeline

1. **Speech Recognition** (Whisper)
   - Audio processed locally by Whisper AI
   - Multilingual model with excellent Turkish support
   - Returns recognized text + confidence score
   - **Privacy-first:** Audio never leaves your machine

2. **Ground-Truth Phonemes** (Phonemizer)
   - Target word converted to IPA phonemes
   - Uses eSpeak NG Turkish backend
   - Produces expected pronunciation sequence

3. **Acoustic Feature Extraction**
   - MFCCs (13 coefficients)
   - Pitch (F0) analysis
   - Formants (F1, F2, F3) via Praat
   - Spectral features
   - Energy characteristics

4. **Phoneme-Level Scoring**
   - Align recognized text with target phonemes
   - Score each phoneme based on acoustic quality
   - Combine Whisper confidence with acoustic scores
   - Generate per-phoneme feedback

5. **Overall Assessment**
   - Weighted score: 40% Recognition + 60% Acoustic
   - Letter grade (A-F)
   - Detailed phoneme breakdown

### Migration from Old Approaches

The previous custom ML training workflow and Azure integration have been **deprecated** and moved to `/backend/deprecated/` and `/docs/deprecated/`. The new Whisper-based approach offers:

âœ… **No training required** - Use Whisper's pre-trained models
âœ… **Zero API costs** - Runs completely locally
âœ… **Better privacy** - Audio never leaves your machine
âœ… **No credentials needed** - No API keys to configure
âœ… **Excellent accuracy** - Production-grade speech recognition
âœ… **Easy deployment** - Just install and run

**Old files archived in:** `/backend/deprecated/`, `/docs/deprecated/`, and `/ml_colab/`

## ğŸ“Š User Flow

1. **Welcome Screen** - Intro and start button
2. **KVKK Consent Form** - Personal info + data consent
3. **Orthodontic Survey** - 8-question Likert scale
4. **Pronunciation Test** - Record 30 Turkish words
5. **Finish Screen** - Thank you + completion

## ğŸ”§ API Endpoints

### Core Endpoints
| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | Health check |
| POST | `/register` | Register new participant |
| POST | `/survey` | Save survey responses |
| POST | `/upload` | Upload audio + analyze |
| GET | `/health` | System status |

### Phoneme API
| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/phoneme/generate` | Generate IPA phonemes for a word |
| POST | `/phoneme/analyze` | Detailed phoneme analysis |
| POST | `/phoneme/batch` | Process multiple words |
| GET | `/phoneme/health` | Check phoneme service status |

**See:** `PHONEME_FEATURE.md` for complete documentation

### Pronunciation Analysis API
| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/analyze/audio` | Legacy heuristic analysis (deprecated) |
| POST | `/analyze` | **Production:** Whisper + Phoneme analysis |

**Production Endpoint Features:**
- Whisper Speech-to-Text recognition (local)
- Phonemizer-based ground-truth phonemes
- Acoustic feature extraction (MFCC, pitch, formants)
- Per-phoneme alignment and scoring
- Overall pronunciation grade (A-F)
- Confidence scores and detailed feedback

**Example Request:**
```bash
curl -X POST http://localhost:8000/analyze \
  -F "file=@recording.wav" \
  -F "word=pencere"
```

**Example Response:**
```json
{
  "word": "pencere",
  "recognized_text": "pencere",
  "recognition_confidence": 0.91,
  "phonemes_target": "p e n dÍ¡Ê’ e É¾ e",
  "segment_scores": {
    "p": 0.96,
    "e": 0.91,
    "n": 0.90,
    "dÍ¡Ê’": 0.88,
    "É¾": 0.85
  },
  "overall": 0.88,
  "grade": "B (Ä°yi)",
  "analysis_method": "whisper_hybrid"
}
```

**See:** `docs/guides/PRONUNCIATION_ANALYSIS_GUIDE.md` for complete documentation

## ğŸ¨ Features

âœ… **Modern UI** - Material UI components with beautiful design
âœ… **Audio Recording** - Browser MediaRecorder API
âœ… **Real-time Feedback** - Instant pronunciation analysis
âœ… **Phoneme Visualization** - IPA phoneme generation with eSpeak-NG
âœ… **Data Privacy** - KVKK compliant, all processing local
âœ… **Zero Cost** - No API fees, runs completely offline
âœ… **Open Source** - Built with open-source tools (Whisper, Phonemizer)
âœ… **Scalable** - Modular architecture, easy to extend  

## ğŸ§ª Testing

### Backend
```bash
cd backend
pytest
```

### Frontend
```bash
cd frontend
npm run test
```

## ğŸ“ Development Notes

### Adding New Words

Edit `frontend/src/components/PronunciationTest.tsx`:
```typescript
const turkishWords = [
  'araba', 'bahÃ§e', // ... add more words
]
```

### Custom Feature Extraction

Modify `extract_acoustic_features()` in:
- `backend/inference.py` - Acoustic analysis logic

### Phoneme Customization

Edit `_generate_phonemes_espeak()` in `backend/inference.py`:
```python
phonemes = phonemize(
    word,
    language='tr',  # Change language
    backend='espeak',
    with_stress=True  # Enable stress markers
)
```

## ğŸ”’ Data Privacy & KVKK Compliance

- All participant data anonymized with UUID
- Audio stored locally, not shared
- Consent explicitly required
- Data used only for research
- Participant can withdraw anytime

## ğŸŒ Deployment

### Production Backend

```bash
cd backend
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
```

### Production Frontend

```bash
cd frontend
npm run build
# Deploy /dist folder to hosting service
```

**Recommended hosts:**
- Frontend: Vercel, Netlify, Cloudflare Pages
- Backend: Railway, Render, DigitalOcean

## ğŸ“š Documentation

Comprehensive documentation is available in the [`docs/`](docs/) folder:

### Quick Links
- ğŸ“– **[Documentation Index](docs/README.md)** - Complete documentation guide
- ğŸš€ **[Quick Start](docs/setup/QUICK_START.md)** - Get started in 5 minutes
- ğŸ¯ **[Pronunciation Guide](docs/guides/PRONUNCIATION_ANALYSIS_GUIDE.md)** - Using the analysis API
- ğŸ”„ **[Whisper Migration](docs/MIGRATION_TO_WHISPER.md)** - Azure to Whisper migration guide
- ğŸ”§ **[Setup Guide](docs/setup/SETUP_GUIDE.md)** - Detailed installation
- ğŸ—ï¸ **[Architecture](docs/architecture/SYSTEM_OVERVIEW.md)** - System design
- ğŸ—‚ï¸ **[Deprecated](docs/deprecated/)** - Archived ML training and Azure docs

### API Documentation
- **Interactive API Docs:** http://localhost:8000/docs (when backend running)
- **Phoneme API:** See [Phoneme Feature Guide](docs/guides/PHONEME_FEATURE.md)

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch: `git checkout -b feature-name`
3. Commit changes: `git commit -m "Add feature"`
4. Push to branch: `git push origin feature-name`
5. Submit pull request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ‘¥ Authors

Created by PhoneticHybrid Team for Turkish linguistics research.

## ğŸ™ Acknowledgments

- **OpenAI Whisper** - Open-source speech recognition
- **Phonemizer** - IPA transcription (eSpeak NG)
- **Praat** - Phonetic analysis toolkit
- **librosa** - Audio feature extraction
- **Material UI** - React component library
- **FastAPI** - Modern Python web framework

## ğŸ“ Support

For issues and questions:
- Open GitHub issue
- Check documentation in `docs/` folder
- Review API docs at http://localhost:8000/docs

---

**Built with â¤ï¸ for Turkish language research**
