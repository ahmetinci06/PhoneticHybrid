# PhoneticHybrid ğŸ™ï¸

A research-grade hybrid (Google Colab + Local) system for Turkish pronunciation analysis using deep learning.

## ğŸ¯ Overview

PhoneticHybrid is a full-stack web platform where participants:
1. Record 30 Turkish words
2. Their audio is analyzed using ML
3. Receive pronunciation accuracy feedback

**Perfect for:** Linguistic research, speech therapy, language learning applications

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SYSTEM ARCHITECTURE                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Frontend   â”‚â”€â”€â”€â”€â”€â–¶â”‚   Backend    â”‚â”€â”€â”€â”€â”€â–¶â”‚  Models   â”‚ â”‚
â”‚  â”‚ React + MUI  â”‚â—€â”€â”€â”€â”€â”€â”‚   FastAPI    â”‚â—€â”€â”€â”€â”€â”€â”‚  PyTorch  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚        â–²                      â–²                      â–²       â”‚
â”‚        â”‚                      â”‚                      â”‚       â”‚
â”‚        â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚        â”‚                   Inference (Local)                 â”‚
â”‚        â”‚                                                      â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚                        â”‚                                     â”‚
â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚                â”‚  Google Colab  â”‚                            â”‚
â”‚                â”‚  GPU Training  â”‚                            â”‚
â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tech Stack

**Frontend:**
- React 18
- Material UI v6
- TypeScript
- Vite

**Backend:**
- FastAPI (Python 3.10+)
- PyTorch 2.1.2
- librosa (audio processing)
- praat-parselmouth (phonetic analysis)

**ML Training:**
- Google Colab (GPU)
- PyTorch neural networks
- Feature extraction: MFCCs, formants, F0, spectral features

## ğŸ“ Project Structure

```
phoneizer/
â”œâ”€â”€ frontend/                # React + MUI application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Welcome.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ConsentForm.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ LikertScale.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ OrthodonticSurvey.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ PronunciationTest.tsx
â”‚   â”‚   â”‚   â””â”€â”€ FinishScreen.tsx
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â”œâ”€â”€ backend/                 # FastAPI server
â”‚   â”œâ”€â”€ main.py             # API endpoints + ML inference
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ ml_colab/               # Google Colab training
â”‚   â”œâ”€â”€ training_notebook.ipynb
â”‚   â”œâ”€â”€ training_environment_setup.txt
â”‚   â””â”€â”€ ai_training_instructions.txt
â”‚
â”œâ”€â”€ models/                 # Trained ML models
â”‚   â””â”€â”€ trained_model.pt   # (created after training)
â”‚
â”œâ”€â”€ data/                   # Participant data
â”‚   â””â”€â”€ participant_xxx/
â”‚       â”œâ”€â”€ info.json
â”‚       â”œâ”€â”€ survey.json
â”‚       â””â”€â”€ kelimeler/
â”‚           â””â”€â”€ *.wav
â”‚
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites

- **Node.js** 18+ and npm
- **Python** 3.10+
- **Google Account** (for Colab training)

### 1. Clone Repository

```bash
cd phoneizer
```

### 2. Setup Backend

```bash
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Setup Frontend

```bash
cd frontend
npm install
```

### 4. Run Development Servers

**Backend:**
```bash
cd backend
python main.py
# Server runs at http://localhost:8000
```

**Frontend:**
```bash
cd frontend
npm run dev
# App runs at http://localhost:3000
```

### 5. Access Application

Open browser: **http://localhost:3000**

## ğŸ“ Training the ML Model

### Step 1: Collect Data
1. Run the web application
2. Have participants complete the pronunciation test
3. Data saved to `/data/participant_xxx/`

### Step 2: Train on Google Colab
1. Upload `/data` folder to Google Drive: `MyDrive/phoneizer/data/`
2. Open `ml_colab/training_notebook.ipynb` in Colab
3. Enable GPU: Runtime â†’ Change runtime type â†’ GPU
4. Run all cells sequentially
5. Download trained model: `models/trained_model.pt`

### Step 3: Deploy Model
1. Copy `trained_model.pt` to local `models/` directory
2. Restart backend server
3. Model will be loaded automatically

**Detailed instructions:** See `ml_colab/ai_training_instructions.txt`

## ğŸ“Š User Flow

1. **Welcome Screen** - Intro and start button
2. **KVKK Consent Form** - Personal info + data consent
3. **Orthodontic Survey** - 8-question Likert scale
4. **Pronunciation Test** - Record 30 Turkish words
5. **Finish Screen** - Thank you + completion

## ğŸ”§ API Endpoints

### Core Endpoints
| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | Health check |
| POST | `/register` | Register new participant |
| POST | `/survey` | Save survey responses |
| POST | `/upload` | Upload audio + analyze |
| GET | `/health` | System status |

### Phoneme API
| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/phoneme/generate` | Generate IPA phonemes for a word |
| POST | `/phoneme/analyze` | Detailed phoneme analysis |
| POST | `/phoneme/batch` | Process multiple words |
| GET | `/phoneme/health` | Check phoneme service status |

**See:** `PHONEME_FEATURE.md` for complete documentation

### Pronunciation Analysis API
| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/analyze/audio` | Analyze pronunciation quality of uploaded .wav |

**Features:**
- Automatic phoneme target generation
- Acoustic feature extraction (MFCC, pitch, formants)
- **ML-based scoring** (0-100) or heuristic fallback
- Per-phoneme detailed feedback
- Overall pronunciation grade (A-F)
- Confidence intervals (with ML)

**See:** `PRONUNCIATION_ANALYSIS_GUIDE.md` for complete documentation

### ML Model Training (New!)
Train a neural network to replace heuristic scoring with learned predictions.

**Quick Start:**
```bash
cd backend
python train_ml_model.py
```

**Features:**
- 57 acoustic features extracted
- Neural network (PyTorch)
- Training on Google Colab (GPU)
- Automatic deployment

**See:** `ML_TRAINING_GUIDE.md` for complete ML training documentation

## ğŸ¨ Features

âœ… **Modern UI** - Material UI components with beautiful design  
âœ… **Audio Recording** - Browser MediaRecorder API  
âœ… **Real-time Feedback** - Instant pronunciation analysis  
âœ… **Phoneme Visualization** - IPA phoneme generation with eSpeak-NG  
âœ… **Data Privacy** - KVKK compliant, encrypted storage  
âœ… **GPU Training** - Fast model training on Colab  
âœ… **Scalable** - Modular architecture, easy to extend  

## ğŸ§ª Testing

### Backend
```bash
cd backend
pytest
```

### Frontend
```bash
cd frontend
npm run test
```

## ğŸ“ Development Notes

### Adding New Words

Edit `frontend/src/components/PronunciationTest.tsx`:
```typescript
const turkishWords = [
  'araba', 'bahÃ§e', // ... add more words
]
```

### Changing Model Architecture

Edit `ml_colab/training_notebook.ipynb`:
```python
model = PronunciationQualityNet(
    input_size=37,
    hidden_sizes=[256, 128, 64],  # Modify layers
    dropout=0.3
)
```

### Custom Feature Extraction

Modify `extract_acoustic_features()` in:
- Training: `ml_colab/training_notebook.ipynb`
- Inference: `backend/main.py`

**Important:** Keep feature extraction identical in both!

## ğŸ”’ Data Privacy & KVKK Compliance

- All participant data anonymized with UUID
- Audio stored locally, not shared
- Consent explicitly required
- Data used only for research
- Participant can withdraw anytime

## ğŸŒ Deployment

### Production Backend

```bash
cd backend
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
```

### Production Frontend

```bash
cd frontend
npm run build
# Deploy /dist folder to hosting service
```

**Recommended hosts:**
- Frontend: Vercel, Netlify, Cloudflare Pages
- Backend: Railway, Render, DigitalOcean

## ğŸ“š Documentation

- **Training Guide:** `ml_colab/ai_training_instructions.txt`
- **Environment Setup:** `ml_colab/training_environment_setup.txt`
- **API Docs:** http://localhost:8000/docs (when backend running)

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch: `git checkout -b feature-name`
3. Commit changes: `git commit -m "Add feature"`
4. Push to branch: `git push origin feature-name`
5. Submit pull request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ‘¥ Authors

Created by PhoneticHybrid Team for Turkish linguistics research.

## ğŸ™ Acknowledgments

- **Phonemizer** - IPA transcription
- **Praat** - Phonetic analysis toolkit
- **librosa** - Audio feature extraction
- **Material UI** - React component library

## ğŸ“ Support

For issues and questions:
- Open GitHub issue
- Check documentation in `ml_colab/`
- Review API docs at `/docs` endpoint

---

**Built with â¤ï¸ for Turkish language research**
